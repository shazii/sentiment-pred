IDEAS for Part5

1. Do BIO name entity recognition first and assign “neutral” sentiment to all entities
	should be a good baseline, at least better than HMM-viterbi

2. from simple observation, our model may not make sense because the sentiment of a NE is often determined by some other words in the sentence. For example, negative: died, bad… positive: favourite, best, love. Maybe we can do

dictionary-based sentiment analysis 
http://fjavieralba.com/basic-sentiment-analysis-with-python.html

Twitter sentiment analysis using Python and NLTK
http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/


Part 5 improvement log

1. Core idea: separate prediction of NER (BIO) and sentiment, as sentiment of NE is often determined by the sentence/its context
2. Methods to improve NER:
    2.1 Emission parameter for observations that did not appear with all states in the train set: e_param[i][obs] = 0.01 / max(count) //Improvement: +2%
    2.2 Lowercase all words //Improvement: +3%
    2.3 Normalize all web links to "http://" //Improvement: +1%

3. Methods to improve Sentiment Prediction
   -effective polar words with counts


Record time: 11pm, Mon 5/12
=============== PART 5 ==============
=============== EN ==============

#Entity in gold data: 662
#Entity in prediction: 732

#Correct Entity : 267
Entity  precision: 0.3648
Entity  recall: 0.4033
Entity  F: 0.3831

#Correct Sentiment : 202
Sentiment  precision: 0.2760
Sentiment  recall: 0.3051
Sentiment  F: 0.2898
=============== ES ==============

#Entity in gold data: 1326
#Entity in prediction: 1404

#Correct Entity : 504
Entity  precision: 0.3590
Entity  recall: 0.3801
Entity  F: 0.3692

#Correct Sentiment : 306
Sentiment  precision: 0.2179
Sentiment  recall: 0.2308
Sentiment  F: 0.2242


=== Perceptron for NER-Sentiment without preprocessing ===
SiyuanDeMBP:sentiment-pred WSY$ python evalResult.py EN/dev.out EN/dev.perceptronNoProc.out

#Entity in gold data: 662
#Entity in prediction: 245

#Correct Entity : 138
Entity  precision: 0.5633
Entity  recall: 0.2085
Entity  F: 0.3043

#Correct Sentiment : 100
Sentiment  precision: 0.4082
Sentiment  recall: 0.1511
Sentiment  F: 0.2205


=== With preprocessing ===

SiyuanDeMBP:sentiment-pred WSY$ python evalResult.py EN/dev.out EN/dev.perceptron.BIO.out

#Entity in gold data: 662
#Entity in prediction: 185

#Correct Entity : 120
Entity  precision: 0.6486
Entity  recall: 0.1813
Entity  F: 0.2834

#Correct Sentiment : 95
Sentiment  precision: 0.5135
Sentiment  recall: 0.1435
Sentiment  F: 0.2243


=== tuning T=20 ===
b_inSpace = 0.5
b_notInSpace = 1
Entity  F: 0.2617
Sentiment  F: 0.2009

b_inSpace = 0
b_notInSpace = 0
Entity  F: 0.3007
Sentiment  F: 0.2116

b_inSpace = 0.1
b_notInSpace = 1
Entity  F: 0.3402
Sentiment  F: 0.2480

b_inSpace = 0.5
b_notInSpace = 1
Entity  F: 0.2995
Sentiment  F: 0.2235

=== No Preprocessing T=20 ===
b_inSpace = 0.5
b_notInSpace = 1
Entity  F: 0.3043
Sentiment  F: 0.2205

b_inSpace = 0
b_notInSpace = 0
Entity  F: 0.2870
Sentiment  F: 0.1921

b_inSpace = 1,1
b_notInSpace = 1,2
Entity  F: 0.2424
Sentiment  F: 0.1882






