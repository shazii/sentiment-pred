IDEAS for Part5

1. Do BIO name entity recognition first and assign “neutral” sentiment to all entities
	should be a good baseline, at least better than HMM-viterbi

2. from simple observation, our model may not make sense because the sentiment of a NE is often determined by some other words in the sentence. For example, negative: died, bad… positive: favourite, best, love. Maybe we can do

dictionary-based sentiment analysis 
http://fjavieralba.com/basic-sentiment-analysis-with-python.html

Twitter sentiment analysis using Python and NLTK
http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/


Part 5 improvement log

1. Core idea: separate prediction of NER (BIO) and sentiment, as sentiment of NE is often determined by the sentence/its context
2. Methods to improve NER:
    2.1 Emission parameter for observations that did not appear with all states in the train set: e_param[i][obs] = 0.01 / max(count) //Improvement: +2%
    2.2 Lowercase all words //Improvement: +3%
    2.3 Normalize all web links to "http://" //Improvement: +1%

3. Methods to improve Sentiment Prediction
    3.1 TODO:Yujia's method
    3.2 effective polar words with counts


Record time: 11pm, Mon 5/12
=============== PART 5 ==============
=============== EN ==============

#Entity in gold data: 662
#Entity in prediction: 732

#Correct Entity : 267
Entity  precision: 0.3648
Entity  recall: 0.4033
Entity  F: 0.3831

#Correct Sentiment : 202
Sentiment  precision: 0.2760
Sentiment  recall: 0.3051
Sentiment  F: 0.2898
=============== ES ==============

#Entity in gold data: 1326
#Entity in prediction: 1404

#Correct Entity : 504
Entity  precision: 0.3590
Entity  recall: 0.3801
Entity  F: 0.3692

#Correct Sentiment : 306
Sentiment  precision: 0.2179
Sentiment  recall: 0.2308
Sentiment  F: 0.2242
